{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUMS Microdata Basic Processing\n",
    "This script consumes Public Use Microdata Sample files (PUMS) files to create a merged, normalized file that can be used for analysis and answer specific queries about demographics in Seattle, specifically:\n",
    "\n",
    "1. Number of residents living below Area Median Income (AMI) thresholds\n",
    "2. Racial breakdown of People of Color living at 60% AMI in Seattle\n",
    "3. Languages represented in the neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and filter for Seattle PUMS\n",
    "data_dir = '../data/'\n",
    "\n",
    "# PUMS IDs for each selected PUMA (Seattle: Downtown, Northeast, Northwest, Southeast, and West)\n",
    "SEATTLE_PUMS = [11601, 11602, 11603, 11604, 11605]\n",
    "\n",
    "# Loading household data for Seattle-only locations\n",
    "DF_HOUSEHOLD = pd.read_csv(data_dir + 'ss16hwa.csv')\n",
    "DF_HOUSEHOLD = DF_HOUSEHOLD[DF_HOUSEHOLD['PUMA'].isin(SEATTLE_PUMS)]\n",
    "\n",
    "# Loading person data for Seattle-only locations\n",
    "DF_PERSON = pd.read_csv(data_dir + 'ss16pwa.csv')\n",
    "DF_PERSON = DF_PERSON[DF_PERSON['PUMA'].isin(SEATTLE_PUMS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AMI data tables. The Area median income thresholds are defined by HUD and a function of family size.\n",
    "# Income limits are published here: \n",
    "# https://www.seattle.gov/Documents/Departments/Housing/PropertyManagers/IncomeRentLimits/2018%20Rent%20and%20Income%20Limits.pdf\n",
    "\n",
    "df_AMI = pd.read_csv(data_dir + 'AMI_2016.csv')\n",
    "df_40 = df_AMI[(df_AMI[\"Threshold\"] == \"40% AMI\")]\n",
    "df_50 = df_AMI[(df_AMI[\"Threshold\"] == \"50% AMI\")]\n",
    "df_60 = df_AMI[(df_AMI[\"Threshold\"] == \"60% AMI\")]\n",
    "df_80 = df_AMI[(df_AMI[\"Threshold\"] == \"80% AMI\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Person Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PUMA  SERIALNO  RAC1P  AGEP  DDRS  DEAR  DEYE  DOUT  DPHY  ENG  \\\n",
      "0  11604       127      6    45   2.0     2     2   2.0   2.0  2.0   \n",
      "1  11604       127      6    67   2.0     2     2   2.0   2.0  3.0   \n",
      "2  11604       747      6    36   2.0     2     2   2.0   2.0  NaN   \n",
      "3  11604       747      6    39   2.0     2     2   2.0   2.0  NaN   \n",
      "4  11604       747      6     8   2.0     2     2   NaN   2.0  NaN   \n",
      "\n",
      "      ...         PINCP    LANP  HISP  PWGTP         race  \\\n",
      "0     ...       16800.0  1960.0     1    122  Asian alone   \n",
      "1     ...           0.0  1960.0     1    130  Asian alone   \n",
      "2     ...      155000.0     NaN     1     74  Asian alone   \n",
      "3     ...       80000.0     NaN     1     80  Asian alone   \n",
      "4     ...           NaN     NaN     1     64  Asian alone   \n",
      "\n",
      "              neighborhood                            hispanic Category  \\\n",
      "0  Southeast, Capital Hill  Not Spanish/Hispanic/Latino origin     LANP   \n",
      "1  Southeast, Capital Hill  Not Spanish/Hispanic/Latino origin     LANP   \n",
      "2  Southeast, Capital Hill  Not Spanish/Hispanic/Latino origin      NaN   \n",
      "3  Southeast, Capital Hill  Not Spanish/Hispanic/Latino origin      NaN   \n",
      "4  Southeast, Capital Hill  Not Spanish/Hispanic/Latino origin      NaN   \n",
      "\n",
      "     Code Description  \n",
      "0  1960.0  Vietnamese  \n",
      "1  1960.0  Vietnamese  \n",
      "2     NaN         NaN  \n",
      "3     NaN         NaN  \n",
      "4     NaN         NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the data set for important indices to track\n",
    "DF_PERSON = DF_PERSON[['PUMA', 'SERIALNO', 'RAC1P', 'AGEP', 'DDRS', 'DEAR', 'DEYE',\n",
    "                        'DOUT', 'DPHY', 'ENG', 'JWTR', 'JWRIP', 'LANX', 'PINCP', 'LANP', 'HISP','PWGTP']]\n",
    "\n",
    "# Add text columns that correspond with race integers\n",
    "DF_PERSON['race'] = np.where(DF_PERSON['RAC1P'] == 1, \"White alone\", \"\")\n",
    "DF_PERSON['race'] = np.where(DF_PERSON['RAC1P'] == 2, \"Black or African American alone\", DF_PERSON['race'])\n",
    "DF_PERSON['race'] = np.where(DF_PERSON['RAC1P'] == 3, \"American Indian alone\", DF_PERSON['race'])\n",
    "DF_PERSON['race'] = np.where(DF_PERSON['RAC1P'] == 4, \"Alaska Native alone\", DF_PERSON['race'])\n",
    "DF_PERSON['race'] = np.where(DF_PERSON['RAC1P'] == 5, \"American Indian and Alaska Native tribes specified; or American Indian or Alaska Native, not specified and no other races\", DF_PERSON['race'])\n",
    "DF_PERSON['race'] = np.where(DF_PERSON['RAC1P'] == 6, \"Asian alone\", DF_PERSON['race'])\n",
    "DF_PERSON['race'] = np.where(DF_PERSON['RAC1P'] == 7, \"Native Hawaiian and Other Pacific Islander alone\", DF_PERSON['race'])\n",
    "DF_PERSON['race'] = np.where(DF_PERSON['RAC1P'] == 8, \"Some Other Race alone\", DF_PERSON['race'])\n",
    "DF_PERSON['race'] = np.where(DF_PERSON['RAC1P'] == 9, \"Two or More Races\", DF_PERSON['race'])\n",
    "\n",
    "# Add text columns that correspond with race integers\n",
    "DF_PERSON['neighborhood'] = np.where(DF_PERSON['PUMA'] == 11601, \"Northwest\", \"\")\n",
    "DF_PERSON['neighborhood'] = np.where(DF_PERSON['PUMA'] == 11602, \"Northeast\", DF_PERSON['neighborhood'])\n",
    "DF_PERSON['neighborhood'] = np.where(DF_PERSON['PUMA'] == 11603, \"Downtown, Queen Anne, Magnolia\", DF_PERSON['neighborhood'])\n",
    "DF_PERSON['neighborhood'] = np.where(DF_PERSON['PUMA'] == 11604, \"Southeast, Capital Hill\", DF_PERSON['neighborhood'])\n",
    "DF_PERSON['neighborhood'] = np.where(DF_PERSON['PUMA'] == 11605, \"West, Duwamish, Beacon Hill\", DF_PERSON['neighborhood'])\n",
    "\n",
    "# Add text columns that correspond with Hispanic origin/integers\n",
    "DF_PERSON['hispanic'] = np.where(DF_PERSON['HISP'] == 1, \"Not Spanish/Hispanic/Latino origin\", \"\")\n",
    "DF_PERSON['hispanic'] = np.where(DF_PERSON['HISP'] >= 2, \"Spanish/Hispanic/Latino origin\", DF_PERSON['hispanic'])\n",
    "\n",
    "# Language text loaded from Codebook\n",
    "df_codebook = pd.read_csv(data_dir + 'Codebook.csv')\n",
    "df_LANP = df_codebook[(df_codebook[\"Category\"] == \"LANP\")]\n",
    "DF_PERSON = pd.merge(left=DF_PERSON, right=df_LANP, how='left', left_on='LANP', right_on='Code')\n",
    "\n",
    "print (DF_PERSON.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Household Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SERIALNO          HINCP  NP  WGTP  AMI_80 HINCP_threshold  AMI_60  AMI_50  \\\n",
      "0       127   17593.321570   2   122     122        Under 60     122     122   \n",
      "1       747  246097.057680   4    74       0         Over 60       0       0   \n",
      "2      1984   55502.740668   3    69      69         Over 60       0       0   \n",
      "3      2319   39794.417838   3    89      89        Under 60      89      89   \n",
      "4      2975   78436.892001   3    77       0         Over 60       0       0   \n",
      "\n",
      "   AMI_40  \n",
      "0     122  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "# Filter the data set for important indices to track\n",
    "DF_HOUSEHOLD = DF_HOUSEHOLD[['SERIALNO','HINCP','NP','WGTP']]\n",
    "# Filter for income > 1\n",
    "DF_HOUSEHOLD = DF_HOUSEHOLD[(DF_HOUSEHOLD[\"HINCP\"] > 1)]\n",
    "\n",
    "# Escalate income to current year\n",
    "# ref http://www.seattle.gov/financedepartment/cpi/documents/US_CPI_History_--_Annual.pdf\n",
    "DF_HOUSEHOLD[\"HINCP\"]  = DF_HOUSEHOLD[\"HINCP\"] * 245.120 / 234.067\n",
    "                        \n",
    "# Limit very large households to 8 ppl to correspond with AMI tables\n",
    "DF_HOUSEHOLD['NP'] = np.where(DF_HOUSEHOLD[\"NP\"] > 8,8,DF_HOUSEHOLD['NP'])\n",
    "\n",
    "NP_total = DF_HOUSEHOLD['NP'].sum()\n",
    "WGTP_total = DF_HOUSEHOLD['WGTP'].sum()\n",
    "\n",
    "# Add a new index for income below 60% of the median\n",
    "# Add columns for number of people in each AMI threshold\n",
    "DF_HOUSEHOLD = pd.merge(left=DF_HOUSEHOLD, right=df_80, how='left', left_on='NP', right_on='NP')\n",
    "#DF_HOUSEHOLD['AMI_80'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], DF_HOUSEHOLD['NP'], 0)\n",
    "DF_HOUSEHOLD['AMI_80'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], DF_HOUSEHOLD['WGTP'], 0)\n",
    "DF_HOUSEHOLD = DF_HOUSEHOLD.drop(['Threshold', 'Amount'], axis=1)\n",
    "\n",
    "DF_HOUSEHOLD = pd.merge(left=DF_HOUSEHOLD, right=df_60, how='left', left_on='NP', right_on='NP')\n",
    "DF_HOUSEHOLD['HINCP_threshold'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], \"Under 60\", \"Over 60\")\n",
    "#DF_HOUSEHOLD['AMI_60'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], DF_HOUSEHOLD['NP'], 0)\n",
    "DF_HOUSEHOLD['AMI_60'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], DF_HOUSEHOLD['WGTP'], 0)\n",
    "DF_HOUSEHOLD = DF_HOUSEHOLD.drop(['Threshold', 'Amount'], axis=1)\n",
    "\n",
    "DF_HOUSEHOLD = pd.merge(left=DF_HOUSEHOLD, right=df_50, how='left', left_on='NP', right_on='NP')\n",
    "#DF_HOUSEHOLD['AMI_50'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], DF_HOUSEHOLD['NP'], 0)\n",
    "DF_HOUSEHOLD['AMI_50'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], DF_HOUSEHOLD['WGTP'], 0)\n",
    "DF_HOUSEHOLD = DF_HOUSEHOLD.drop(['Threshold', 'Amount'], axis=1)\n",
    "\n",
    "DF_HOUSEHOLD = pd.merge(left=DF_HOUSEHOLD, right=df_40, how='left', left_on='NP', right_on='NP')\n",
    "#DF_HOUSEHOLD['AMI_40'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], DF_HOUSEHOLD['NP'], 0)\n",
    "DF_HOUSEHOLD['AMI_40'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], DF_HOUSEHOLD['WGTP'], 0)\n",
    "DF_HOUSEHOLD = DF_HOUSEHOLD.drop(['Threshold', 'Amount'], axis=1)\n",
    "\n",
    "DF_HOUSEHOLD = pd.merge(left=DF_HOUSEHOLD, right=df_40, how='left', left_on='NP', right_on='NP')\n",
    "#DF_HOUSEHOLD['AMI_40'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], DF_HOUSEHOLD['NP'], 0)\n",
    "DF_HOUSEHOLD['AMI_40'] = np.where(DF_HOUSEHOLD['HINCP'] <= DF_HOUSEHOLD['Amount'], DF_HOUSEHOLD['WGTP'], 0)\n",
    "DF_HOUSEHOLD = DF_HOUSEHOLD.drop(['Threshold', 'Amount'], axis=1)\n",
    "\n",
    "# Calculate percentages for each household\n",
    "#HINCP_UNDER80 = DF_HOUSEHOLD['AMI_80'].sum() / WGTP_total\n",
    "#HINCP_UNDER60 = DF_HOUSEHOLD['AMI_60'].sum() / WGTP_total\n",
    "#HINCP_UNDER50 = DF_HOUSEHOLD['AMI_50'].sum() / WGTP_total\n",
    "#HINCP_UNDER40 = DF_HOUSEHOLD['AMI_40'].sum() / WGTP_total\n",
    "\n",
    "#print(\"Number of Seattle residents living at-\")\n",
    "#print(\"80% AMI:\", \"{:.0%}\".format(HINCP_UNDER80))\n",
    "#print(\"60% AMI:\", \"{:.0%}\".format(HINCP_UNDER60))\n",
    "#print(\"50% AMI:\", \"{:.0%}\".format(HINCP_UNDER50))\n",
    "#print(\"40% AMI:\", \"{:.0%}\".format(HINCP_UNDER40))\n",
    "\n",
    "print (DF_HOUSEHOLD.head())\n",
    "#print (, HINCP_UNDER60, HINCP_UNDER50, HINCP_UNDER40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged Household and Person Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Seattle residents living at-\n",
      "80% AMI: 30%\n",
      "60% AMI: 22%\n",
      "50% AMI: 18%\n",
      "40% AMI: 14%\n",
      "    PUMA  SERIALNO  RAC1P  AGEP  DDRS  DEAR  DEYE  DOUT  DPHY  ENG  ...    \\\n",
      "0  11604       127      6    45   2.0     2     2   2.0   2.0  2.0  ...     \n",
      "1  11604       127      6    67   2.0     2     2   2.0   2.0  3.0  ...     \n",
      "2  11604       747      6    36   2.0     2     2   2.0   2.0  NaN  ...     \n",
      "3  11604       747      6    39   2.0     2     2   2.0   2.0  NaN  ...     \n",
      "4  11604       747      6     8   2.0     2     2   NaN   2.0  NaN  ...     \n",
      "\n",
      "     Code  Description         HINCP   NP   WGTP  AMI_80  HINCP_threshold  \\\n",
      "0  1960.0   Vietnamese   17593.32157  2.0  122.0     122         Under 60   \n",
      "1  1960.0   Vietnamese   17593.32157  2.0  122.0     130         Under 60   \n",
      "2     NaN          NaN  246097.05768  4.0   74.0       0          Over 60   \n",
      "3     NaN          NaN  246097.05768  4.0   74.0       0          Over 60   \n",
      "4     NaN          NaN  246097.05768  4.0   74.0       0          Over 60   \n",
      "\n",
      "  AMI_60 AMI_50 AMI_40  \n",
      "0    122    122    122  \n",
      "1    130    130    130  \n",
      "2      0      0      0  \n",
      "3      0      0      0  \n",
      "4      0      0      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge data set - left join on each Person, so NP should now be set to 1\n",
    "DF_MERGED = pd.DataFrame()\n",
    "DF_MERGED = pd.merge(left=DF_PERSON, right=DF_HOUSEHOLD, how='left', left_on='SERIALNO', right_on='SERIALNO')\n",
    "\n",
    "# Because the merged data is at the Person level, change weight to PWGTP\n",
    "DF_MERGED['AMI_80'] = np.where(DF_MERGED['AMI_80'] > 0, DF_MERGED['PWGTP'], 0)\n",
    "DF_MERGED['AMI_60'] = np.where(DF_MERGED['AMI_60'] > 0, DF_MERGED['PWGTP'], 0)\n",
    "DF_MERGED['AMI_50'] = np.where(DF_MERGED['AMI_50'] > 0, DF_MERGED['PWGTP'], 0)\n",
    "DF_MERGED['AMI_40'] = np.where(DF_MERGED['AMI_40'] > 0, DF_MERGED['PWGTP'], 0)\n",
    "\n",
    "# Calculate percentages for each household\n",
    "PWGTP_total = DF_MERGED['PWGTP'].sum()\n",
    "\n",
    "HINCP_UNDER80 = DF_MERGED['AMI_80'].sum() / PWGTP_total\n",
    "HINCP_UNDER60 = DF_MERGED['AMI_60'].sum() / PWGTP_total\n",
    "HINCP_UNDER50 = DF_MERGED['AMI_50'].sum() / PWGTP_total\n",
    "HINCP_UNDER40 = DF_MERGED['AMI_40'].sum() / PWGTP_total\n",
    "\n",
    "print(\"Number of Seattle residents living at-\")\n",
    "print(\"80% AMI:\", \"{:.0%}\".format(HINCP_UNDER80))\n",
    "print(\"60% AMI:\", \"{:.0%}\".format(HINCP_UNDER60))\n",
    "print(\"50% AMI:\", \"{:.0%}\".format(HINCP_UNDER50))\n",
    "print(\"40% AMI:\", \"{:.0%}\".format(HINCP_UNDER40))\n",
    "\n",
    "DF_MERGED.to_csv(data_dir + 'PUMS_merged.csv', mode='w', header=True, index=False)\n",
    "\n",
    "print (DF_MERGED.head())\n",
    "\n",
    "# Create classification for households under 60% AMI\n",
    "DF_MERGED = DF_MERGED[DF_MERGED[\"HINCP_threshold\"] == \"Under 60\"]\n",
    "\n",
    "# Under 60% aggregated by Hispanic/spanish/latino orgin (of any race), calculate percentages of total, save as csv\n",
    "DF_AGGREGATED_HISPANIC_ORIGIN = pd.DataFrame()\n",
    "#DF_AGGREGATED_HISPANIC_ORIGIN = DF_MERGED.groupby(['hispanic'], as_index=False).agg({'NP':[sum]})\n",
    "DF_AGGREGATED_HISPANIC_ORIGIN = DF_MERGED.groupby(['hispanic'], as_index=False).agg({'PWGTP':[sum]})\n",
    "\n",
    "#NP_TOTAL = DF_AGGREGATED_HISPANIC_ORIGIN['NP'].sum()\n",
    "NP_TOTAL = DF_AGGREGATED_HISPANIC_ORIGIN['PWGTP'].sum()\n",
    "\n",
    "#DF_AGGREGATED_HISPANIC_ORIGIN[\"pct\"] = DF_AGGREGATED_HISPANIC_ORIGIN[\"NP\"] / NP_TOTAL\n",
    "DF_AGGREGATED_HISPANIC_ORIGIN[\"pct\"] = DF_AGGREGATED_HISPANIC_ORIGIN[\"PWGTP\"] / NP_TOTAL\n",
    "\n",
    "DF_AGGREGATED_HISPANIC_ORIGIN.columns = DF_AGGREGATED_HISPANIC_ORIGIN.columns.droplevel(level=1)\n",
    "DF_AGGREGATED_HISPANIC_ORIGIN.to_csv(data_dir + 'AGGREGATED_HISPANIC_ORIGIN.csv', mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Racial breakdown of People of Color living at 60% AMI in Seattle\n",
      "                                                race  PWGTP       pct\n",
      "0                              American Indian alone    461  0.005836\n",
      "1  American Indian and Alaska Native tribes speci...     68  0.000861\n",
      "2                                        Asian alone  30583  0.387156\n",
      "3                    Black or African American alone  25406  0.321619\n",
      "4   Native Hawaiian and Other Pacific Islander alone   1725  0.021837\n",
      "5                              Some Other Race alone   4662  0.059017\n",
      "6                                  Two or More Races  16089  0.203674\n",
      "Racial breakdown of Spanish/Hispanic/Latino origin (of any race) living at 60% AMI in Seattle\n",
      "                             hispanic   PWGTP       pct\n",
      "0  Not Spanish/Hispanic/Latino origin  141290  0.926729\n",
      "1      Spanish/Hispanic/Latino origin   11171  0.073271\n",
      "Further breakdown: What geographic neighborhoods are represented in this data\n",
      "                      neighborhood  \\\n",
      "0   Downtown, Queen Anne, Magnolia   \n",
      "1   Downtown, Queen Anne, Magnolia   \n",
      "2   Downtown, Queen Anne, Magnolia   \n",
      "3   Downtown, Queen Anne, Magnolia   \n",
      "4   Downtown, Queen Anne, Magnolia   \n",
      "5                        Northeast   \n",
      "6                        Northeast   \n",
      "7                        Northeast   \n",
      "8                        Northeast   \n",
      "9                        Northwest   \n",
      "10                       Northwest   \n",
      "11                       Northwest   \n",
      "12                       Northwest   \n",
      "13                       Northwest   \n",
      "14         Southeast, Capital Hill   \n",
      "15         Southeast, Capital Hill   \n",
      "16         Southeast, Capital Hill   \n",
      "17         Southeast, Capital Hill   \n",
      "18         Southeast, Capital Hill   \n",
      "19     West, Duwamish, Beacon Hill   \n",
      "20     West, Duwamish, Beacon Hill   \n",
      "21     West, Duwamish, Beacon Hill   \n",
      "22     West, Duwamish, Beacon Hill   \n",
      "23     West, Duwamish, Beacon Hill   \n",
      "24     West, Duwamish, Beacon Hill   \n",
      "\n",
      "                                                 race  PWGTP       pct  \n",
      "0                               American Indian alone    288  0.003646  \n",
      "1                                         Asian alone   6753  0.085488  \n",
      "2                     Black or African American alone   2024  0.025622  \n",
      "3                               Some Other Race alone    621  0.007861  \n",
      "4                                   Two or More Races   1733  0.021938  \n",
      "5                                         Asian alone   7882  0.099780  \n",
      "6                     Black or African American alone   3506  0.044383  \n",
      "7                               Some Other Race alone    509  0.006444  \n",
      "8                                   Two or More Races   1700  0.021521  \n",
      "9                                         Asian alone   1949  0.024673  \n",
      "10                    Black or African American alone   1536  0.019445  \n",
      "11   Native Hawaiian and Other Pacific Islander alone    113  0.001430  \n",
      "12                              Some Other Race alone    265  0.003355  \n",
      "13                                  Two or More Races   3151  0.039889  \n",
      "14                              American Indian alone    131  0.001658  \n",
      "15                                        Asian alone   3293  0.041687  \n",
      "16                    Black or African American alone   8162  0.103324  \n",
      "17   Native Hawaiian and Other Pacific Islander alone   1612  0.020407  \n",
      "18                                  Two or More Races   4787  0.060600  \n",
      "19                              American Indian alone     42  0.000532  \n",
      "20  American Indian and Alaska Native tribes speci...     68  0.000861  \n",
      "21                                        Asian alone  10706  0.135529  \n",
      "22                    Black or African American alone  10178  0.128845  \n",
      "23                              Some Other Race alone   3267  0.041358  \n",
      "24                                  Two or More Races   4718  0.059726  \n",
      "Languages represented in the neighborhoods\n",
      "                      neighborhood              Description  PWGTP       pct\n",
      "0   Downtown, Queen Anne, Magnolia                  Amharic    384  0.010574\n",
      "1   Downtown, Queen Anne, Magnolia                  Burmese   1031  0.028391\n",
      "2   Downtown, Queen Anne, Magnolia                Cantonese    606  0.016688\n",
      "3   Downtown, Queen Anne, Magnolia                  Chinese     70  0.001928\n",
      "4   Downtown, Queen Anne, Magnolia                 Filipino    267  0.007353\n",
      "5   Downtown, Queen Anne, Magnolia                   German     68  0.001873\n",
      "6   Downtown, Queen Anne, Magnolia                 Mandarin    301  0.008289\n",
      "7   Downtown, Queen Anne, Magnolia                  Russian     59  0.001625\n",
      "8   Downtown, Queen Anne, Magnolia                    Shona    147  0.004048\n",
      "9   Downtown, Queen Anne, Magnolia                  Spanish    486  0.013383\n",
      "10  Downtown, Queen Anne, Magnolia                  Tagalog    142  0.003910\n",
      "11  Downtown, Queen Anne, Magnolia               Vietnamese    211  0.005810\n",
      "12                       Northeast                  Amharic   1326  0.036515\n",
      "13                       Northeast                   Arabic     97  0.002671\n",
      "14                       Northeast                  Bengali     99  0.002726\n",
      "15                       Northeast                Cantonese    583  0.016054\n",
      "16                       Northeast                  Chinese   2985  0.082200\n",
      "17                       Northeast                 Japanese    168  0.004626\n",
      "18                       Northeast                   Korean   1045  0.028777\n",
      "19                       Northeast                 Mandarin    156  0.004296\n",
      "20                       Northeast                  Punjabi    110  0.003029\n",
      "21                       Northeast                  Spanish    290  0.007986\n",
      "22                       Northeast                     Thai    115  0.003167\n",
      "23                       Northeast               Vietnamese   1086  0.029906\n",
      "24                       Northwest                  Amharic    215  0.005921\n",
      "25                       Northwest                  Chinese    549  0.015118\n",
      "26                       Northwest                 Japanese    117  0.003222\n",
      "27                       Northwest                   Korean    155  0.004268\n",
      "28                       Northwest                      Lao    133  0.003662\n",
      "29                       Northwest                  Tagalog   1766  0.048631\n",
      "30         Southeast, Capital Hill                Cantonese    240  0.006609\n",
      "31         Southeast, Capital Hill                  Chinese    303  0.008344\n",
      "32         Southeast, Capital Hill                 Japanese    106  0.002919\n",
      "33         Southeast, Capital Hill                 Mandarin    168  0.004626\n",
      "34         Southeast, Capital Hill                    Oromo    366  0.010079\n",
      "35         Southeast, Capital Hill                   Somali    282  0.007766\n",
      "36         Southeast, Capital Hill                  Swahili    755  0.020791\n",
      "37         Southeast, Capital Hill                  Tagalog    106  0.002919\n",
      "38         Southeast, Capital Hill                     Thai    424  0.011676\n",
      "39         Southeast, Capital Hill               Vietnamese   1448  0.039874\n",
      "40     West, Duwamish, Beacon Hill                  Amharic    373  0.010272\n",
      "41     West, Duwamish, Beacon Hill                Cantonese    638  0.017569\n",
      "42     West, Duwamish, Beacon Hill                  Chinese   2414  0.066476\n",
      "43     West, Duwamish, Beacon Hill                    Hindi    162  0.004461\n",
      "44     West, Duwamish, Beacon Hill                  Italian     92  0.002533\n",
      "45     West, Duwamish, Beacon Hill                 Japanese    109  0.003002\n",
      "46     West, Duwamish, Beacon Hill                    Khmer    174  0.004792\n",
      "47     West, Duwamish, Beacon Hill                   Korean    238  0.006554\n",
      "48     West, Duwamish, Beacon Hill                 Mandarin    523  0.014402\n",
      "49     West, Duwamish, Beacon Hill                    Oromo   1179  0.032467\n",
      "50     West, Duwamish, Beacon Hill    Other Mande languages   1120  0.030842\n",
      "51     West, Duwamish, Beacon Hill  Other languages of Asia    171  0.004709\n",
      "52     West, Duwamish, Beacon Hill                  Punjabi    111  0.003057\n",
      "53     West, Duwamish, Beacon Hill                   Somali   3168  0.087239\n",
      "54     West, Duwamish, Beacon Hill                  Spanish   2797  0.077023\n",
      "55     West, Duwamish, Beacon Hill                  Tagalog   2100  0.057829\n",
      "56     West, Duwamish, Beacon Hill                 Tigrinya     74  0.002038\n",
      "57     West, Duwamish, Beacon Hill               Vietnamese   1906  0.052487\n"
     ]
    }
   ],
   "source": [
    "# Create classification for households of POC\n",
    "DF_MERGED = DF_MERGED[DF_MERGED[\"race\"] != \"White alone\"]\n",
    "\n",
    "# Under 60% aggregated by race, calculate percentages of total, save as csv\n",
    "DF_AGGREGATED_RACE = pd.DataFrame()\n",
    "#DF_AGGREGATED_RACE = DF_MERGED.groupby(['race'], as_index=False).agg({'NP':[sum]})\n",
    "#NP_TOTAL = DF_AGGREGATED_RACE['NP'].sum()\n",
    "#DF_AGGREGATED_RACE[\"pct\"] = DF_AGGREGATED_RACE[\"NP\"] / NP_TOTAL\n",
    "DF_AGGREGATED_RACE = DF_MERGED.groupby(['race'], as_index=False).agg({'PWGTP':[sum]})\n",
    "PWGTP_TOTAL = DF_AGGREGATED_RACE['PWGTP'].sum()\n",
    "DF_AGGREGATED_RACE[\"pct\"] = DF_AGGREGATED_RACE[\"PWGTP\"] / PWGTP_TOTAL\n",
    "DF_AGGREGATED_RACE.columns = DF_AGGREGATED_RACE.columns.droplevel(level=1)\n",
    "DF_AGGREGATED_RACE.to_csv(data_dir + 'Aggregated_race.csv', mode='w', header=True, index=False)\n",
    "\n",
    "# Aggregate by race and neighborhood, calculate percentage of total, save as csv\n",
    "DF_AGGREGATED_RACE_NEIGHB = pd.DataFrame()\n",
    "#DF_AGGREGATED_RACE_NEIGHB = DF_MERGED.groupby(['neighborhood', 'race'], as_index=False).agg({'NP':[sum]})\n",
    "#DF_AGGREGATED_RACE_NEIGHB.columns = DF_AGGREGATED_RACE_NEIGHB.columns.droplevel(level=1)\n",
    "#NP_TOTAL = DF_AGGREGATED_RACE_NEIGHB['NP'].sum()\n",
    "#DF_AGGREGATED_RACE_NEIGHB[\"pct\"] = DF_AGGREGATED_RACE_NEIGHB[\"NP\"] / NP_TOTAL\n",
    "DF_AGGREGATED_RACE_NEIGHB = DF_MERGED.groupby(['neighborhood', 'race'], as_index=False).agg({'PWGTP':[sum]})\n",
    "DF_AGGREGATED_RACE_NEIGHB.columns = DF_AGGREGATED_RACE_NEIGHB.columns.droplevel(level=1)\n",
    "PWGTP_TOTAL = DF_AGGREGATED_RACE_NEIGHB['PWGTP'].sum()\n",
    "DF_AGGREGATED_RACE_NEIGHB[\"pct\"] = DF_AGGREGATED_RACE_NEIGHB[\"PWGTP\"] / PWGTP_TOTAL\n",
    "DF_AGGREGATED_RACE_NEIGHB.to_csv(data_dir + 'Aggregated_race_neighb.csv', mode='w', header=True, index=False)\n",
    "\n",
    "# Aggregate by language and neighborhood, calulate percentages, save as csv\n",
    "DF_AGGREGATED_LANG_NEIGHB = pd.DataFrame()\n",
    "#DF_AGGREGATED_LANG_NEIGHB = DF_MERGED.groupby(['neighborhood','Description'], as_index=False).agg({'NP':['sum']})\n",
    "#DF_AGGREGATED_LANG_NEIGHB.columns = DF_AGGREGATED_LANG_NEIGHB.columns.droplevel(level=1)\n",
    "#NP_TOTAL = DF_AGGREGATED_LANG_NEIGHB['NP'].sum()\n",
    "DF_AGGREGATED_LANG_NEIGHB = DF_MERGED.groupby(['neighborhood','Description'], as_index=False).agg({'PWGTP':['sum']})\n",
    "DF_AGGREGATED_LANG_NEIGHB.columns = DF_AGGREGATED_LANG_NEIGHB.columns.droplevel(level=1)\n",
    "PWGTP_TOTAL = DF_AGGREGATED_LANG_NEIGHB['PWGTP'].sum()\n",
    "DF_AGGREGATED_LANG_NEIGHB[\"pct\"] = DF_AGGREGATED_LANG_NEIGHB[\"PWGTP\"] / PWGTP_TOTAL\n",
    "DF_AGGREGATED_LANG_NEIGHB.to_csv(data_dir + 'Aggregated_lang_neighb.csv', mode='w', header=True, index=False)\n",
    "\n",
    "print(\"Racial breakdown of People of Color living at 60% AMI in Seattle\")\n",
    "print(DF_AGGREGATED_RACE)\n",
    "\n",
    "print(\"Racial breakdown of Spanish/Hispanic/Latino origin (of any race) living at 60% AMI in Seattle\")\n",
    "print(DF_AGGREGATED_HISPANIC_ORIGIN)\n",
    "\n",
    "print(\"Further breakdown: What geographic neighborhoods are represented in this data\")\n",
    "print(DF_AGGREGATED_RACE_NEIGHB)\n",
    "\n",
    "print(\"Languages represented in the neighborhoods\")\n",
    "print(DF_AGGREGATED_LANG_NEIGHB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-569394a4ec47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mLanguages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mLanguages\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Other English-based Creole languages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mwordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLanguages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-569394a4ec47>\u001b[0m in \u001b[0;36mwordCloud\u001b[0;34m(Text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Sudo pip install wordcloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageColorGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "def wordCloud(Text):\n",
    "    \n",
    "    # Sudo pip install wordcloud\n",
    "    from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from os import path\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    # Shape masked wordcloud\n",
    "    # Mask = np.array(Image.open(\"./data/map.png\"))\n",
    "    # Image_colors = ImageColorGenerator(Mask)\n",
    "\n",
    "    # text wordcloud\n",
    "    # Wordcloud = WordCloud(max_font_size=100, width = 1200, height = 600, mode = 'RGBA', background_color = 'white').generate(' '.join(Text))\n",
    "    wordcloud = WordCloud(collocations=False, max_font_size=100, width =1200, height =600, background_color ='white', colormap=\"ocean\").generate(' '.join(Text))\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    wordcloud.to_file(\"./Data/PUMS_Languages.png\")\n",
    "\n",
    "Languages = DF_PERSON['Description'].tolist()\n",
    "Languages = [x for x in Languages if str(x) != 'nan']\n",
    "Languages = [x for x in Languages if str(x) != 'Nan']\n",
    "Languages = [x for x in Languages if str(x) != 'Other languages of Asia']\n",
    "Languages = [x for x in Languages if str(x) != 'Other Mande languages']\n",
    "Languages = [x for x in Languages if str(x) != 'Other Indo-Iranian languages']\n",
    "Languages = [x for x in Languages if str(x) != 'Other Philippine languages']\n",
    "Languages = [x for x in Languages if str(x) != 'Other and unspecified languages']\n",
    "Languages = [x for x in Languages if str(x) != 'Other Indo-European languages']\n",
    "Languages = [x for x in Languages if str(x) != 'Other Niger-Congo languages']\n",
    "Languages = [x for x in Languages if str(x) != 'Other Central and South American languages']\n",
    "Languages = [x for x in Languages if str(x) != 'Other English-based Creole languages']\n",
    "\n",
    "wordCloud(Languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
